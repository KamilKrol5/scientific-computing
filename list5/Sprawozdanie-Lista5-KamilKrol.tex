\documentclass[]{article}
\usepackage[utf8]{inputenc}
\usepackage{polski}
\usepackage{listings}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{geometry}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{enumerate}
\usepackage{tabularx}
\usepackage[font=small]{caption}
\usepackage[ruled,noend]{algorithm2e}
\usepackage{bm}
\SetAlgorithmName{Algorytm}{algorytm}{Algorytmy}
\DeclareGraphicsExtensions{.png}
\graphicspath{ {./} }
\geometry{
	a4paper,
	left=25mm,
	right = 25mm,
	top=20mm,
	bottom=20mm
}
%%\hyphenchar\font=-1

\title{
	Sprawozdanie \\
	\large 
	Obliczenia naukowe - lista 5}
\author{Kamil Król}
\date{244949}
\newcommand{\mA}{\bm{A}}
\newcommand{\mB}{\bm{B}}
\newcommand{\mC}{\bm{C}}
\newcommand{\mL}{\bm{L}}
\newcommand{\mU}{\bm{U}}
\newcommand{\mZ}{\bm{0}}
\newcommand{\vb}{\bm{b}}
\newcommand{\vx}{\bm{x}}
\newcommand{\R}{\mathbb{R}}

\begin{document}
	
	\maketitle
	
	\section*{Opis problemu oraz struktury danych}
	Celem listy jest rozwiązanie układu równań liniowych: 
	$\mA\vx = \vb$,
	dla danej macierzy $\mA \in \R^{n\times n}$ 
	i wektora prawych stron $\vb \in \R^n$, gdzie $n \geq 4$. \\
	
	\noindent Zgodnie z treścią listy macierz $\mA$ jest rzadką macierzą (tj. mającą dużo elementów zerowych) blokową o następującej strukturze:
	\begin{equation}
	\mA =
	\left(\begin{array}{ccccccc}
	\mA_1 & \mC_1 & \mZ & \mZ & \mZ & \cdots & \mZ \\
	\mB_2 & \mA_2 & \mC_2 & \mZ & \mZ  & \cdots & \mZ \\
	\mZ  & \mB_3 & \mA_3 & \mC_3 & \mZ  & \cdots & \mZ \\
	\vdots & \ddots & \ddots & \ddots & \ddots & \ddots & \vdots\\
	\mZ   & \cdots & \mZ  & \mB_{v-2} & \mA_{v-2} & \mC_{v-2} & \mZ \\
	\mZ  & \cdots & \mZ  &  \mZ &\mB_{v-1} & \mA_{v-1} & \mC_{v-1}  \\
	\mZ  & \cdots & \mZ & \mZ & \mZ& \mB_{v} & \mA_{v}  \\
	\end{array}\right),
	\end{equation} 
	$v = n/\ell$, zakładając że $n$ jest podzielne przez $\ell$, gdzie $\ell \geq 2$ jest rozmiarem wszystkich kwadratowych macierzy wewnętrznych (bloków) $\mA_i$, $\mB_i$, $\mC_i$, $\mZ$. \\
	
	\noindent Macierze oznaczone przez $\mZ$ są macierzami zerowymi tzn. $\mZ \in \R^{\ell\times \ell}$. Macierze $\mA_i$, $\mB_i$, $\mC_i$, są następującej postaci:
	\begin{enumerate}[(i)]
		\item $\mA_i \in \R^{\ell\times \ell}$,   $i = 1, \ldots,v$ -- macierze gęste,
		\item $\mB_i \in \R^{\ell\times \ell}$,   $i = 2, \ldots,v$ -- macierze mające tylko dwie ostatnie kolumny niezerowe:
		\begin{equation}
		\mB_i =
		\left(\begin{array}{ccccc}
		0 & \cdots & 0 & b_{1\,\ell-1}^i & b_{1\,\ell}^i \\
		0 & \cdots & 0 & b_{2\,\ell-1}^i & b_{2\,\ell}^i \\
		\vdots & & \vdots & \vdots & \vdots \\
		0 & \cdots & 0 & b_{\ell\,\ell-1}^i & b_{\ell\,\ell}^i \\
		\end{array}\right),
		\end{equation} 
		\item $\mC_i \in \R^{\ell\times \ell}$,   $i = 1, \ldots,v\!-\!1$ -- macierze diagonalne:
		\begin{equation}
		\mC_i =
		\left(\begin{array}{ccccc}
		c_{1}^i & 0 & 0 & \cdots & 0  \\
		0 &  c_{2}^i &  0 & \cdots & 0  \\
		\vdots &  \ddots &  \ddots & \ddots & \vdots  \\
		0 & \cdots & 0 &  c_{\ell-1}^i & 0 \\
		0 & \cdots & 0 &  0 & c_{\ell}^i \\
		\end{array}\right).
		\end{equation} 
	\end{enumerate}

	Dodatkową informacją o danych jest ich duży rozmiar. W konsekwencji wyklucza to pamiętanie macierzy $\mA$ jako tablicę o wymiarach $n \times n$ oraz użycie standardowych (bibliotecznych) algorytmów dla macierzy gęstych tj. takich, gdzie
	nie zakłada się dużej liczby elementów zerowych. Zatem dodatkowym wymaganiem co do zadania jest specjalna struktura pamiętająca efektywnie macierz $\mA$. Taka która pamięta tylko elementy niezerowe macierzy $\mA$. W tym celu w moich programach użyłem biblioteki \textit{SparseArrays}, która pamięta tylko elementy niezerowe. W naszych rozważaniach założymy, że możemy uzyskać dostęp do elementów macierzy w czasie stałym -- $O(1)$. W rzeczywistości tak nie jest. \\
	Ponadto konieczna jest modyfikacja standardowych algorytmów tak, aby uwzględniały one specyficzną postać macierzy $\mA$, tj.
	jej rzadkość, regularność występowania elementów zerowych i niezerowych.\\
	
	\noindent Zaimplementowane przeze mnie algorytmy (napisane w języku Julia i opisane poniżej) działają na macierzy transponowanej, ze względu na optymalizację tzn. dostęp do elementów po kolumnach jest szybszy niż po wierszach. W dalszych rozważaniach pominiemy ten fakt gdyż transpozycja nie zmienia wewnętrznej struktury macierzy $\mA$ oraz nie zmienia ogólnej idei algorytmu.
	Odnośnik do dokumentacji: 
	\href{https://docs.julialang.org/en/v1/stdlib/SparseArrays/}{julialang - SparseArrays}.
	

	\subsection*{Opis metody eliminacji Gaussa bez wyboru elementu głównego}
	Ideą eliminajci Gaussa jest to aby początkowy układ równań sprowadzić do układu prostszego. Dokładniej chodzi o sprowadzenie macierzy A do postaci macierzy trójkątnej górnej. W celu doprowadzenia macierzy do takiej postaci algorytm posługuje się podstawowymi operacjami na macierzy tzn. dodawanie, odejmowanie wierszy oraz mnożenie wierszy przez pewnien niezerowy współczynnik. \\
	Dokładniej, proces polega na eliminowaniu (zerowaniu) elementów znajdujących się w pod przekątną macierzy.
	Zatem dla kolumny pierwszej będziemy chcieli wyzerować wszystkie elementy znajdujące się pod pierwszym elementem w tej kolumnie, dla kolumny drugiej -- wszystkie elementy pod drugim (patrząc od góry) elementem w danej kolumnie. Bardziej formalnie, naszym celem będzie wyeliminowanie niewiadomej $x_1$ ze wszystkich $n-1$ pozostałych równań (czyli wszystkich poza pierwszym). Dla $i = 2,\ldots,n$ będziemy odejmować odpowiednią wielokrotność równania pierwszego od $i$-tego równania zerując przy tym współczynnik przy $x_1$ w $i$-tym równaniu. \\
	Ogólnie dla macierzy A i jej elementów $a_{ij}$, gdzie $i,j = 1,\ldots,n$ i dla jej $k$-tej kolumny, będziemy zerować wszystkie elementy poniżej elementu na przekątnej w tej kolumnie, czyli $a_{kk}$. Dla $i = k+1,\ldots,n$ będziemy odejmować odpowiednią wielokrotność równania $k$-tego od $i$-tego równania zerując przy tym współczynnik przy $x_k$ w $i$-tym równaniu. Inaczej aby wyzerować to $x_k$ będziemy musieli pomnożyć wiersz $k$ przez pewien współczynnik $\psi_{ik}$, króty dalej będziemy nazywać mnożnikiem, a następnie odjąć go od $i$-tego wiersza. Łatwo zauważyć, że mnożnik ten możemy obliczyć, ze wzoru $\psi_{ik}$ = $\frac{a_{ik}}{a_{kk}}$. Widać też, że w przypadku kiedy na diagonali pojawi się element równy zero nasz algorytm nie zadziała, ponieważ pojawi się konieczność dzielenia przez zero. \\
	Zanim zobaczymy jak można rozwiązać ten problem musimy przytoczyć jedną z własności układu równań Ax=b. Mianowicie, wiersze macierzy A i odpowiadające im wartości w wektorze b możemy dowolnie ze sobą zamieniać. Nie zmianiamy w ten sposób układu równań.
	Zwróćmy również uwagę na fakt, że aby istniało rozwiązanie tego równania macierz A musi być nieosobliwa. 
	Teraz możemy przedstawić sposób na uniknięcie dzielenia przez 0. 
	\subsection*{Opis metody eliminacji Gaussa częściowym wyborem elementu głównego}
	Przedstawiona poniżej metoda nosi nazwę metody eliminacjii Gaussa z częściowym wyborem elementu głównego.
	Czym jest element główny? Jest to element macierzy znajdujący się na diagonali. Dla $k$-tej kolumny, elementem głównym będzie element $a_{kk}$ macierzy A. Jest to również ten element przez który dzielimy chcąc obliczyć mnożnik $\psi_{ik}$ ($k$ oraz $i$ są opisane tak samo jak w poprzednim paragrafie). Częściowy wybór polega na wybraniu największego elementu co do wartości bezwzględnej z danej kolumny $k$ oraz zamianie wierszy tak aby ten element stał się elementem głównym -- elementem na diagonali. Możemy to zrobić, ponieważ macierz A jest nieosobliwa. \\
	Zamiana wierszy macierzy jest kosztownym prcesem, który może być zastąpiony przez wektor permutacji wierszy $p$. Zapamiętujemy w nim, na którym miejscu aktualnie znajduje się dany wiersz. Zatem jedyna różnica w samym algorytmie będzie taka, że zamiast odwoływać się do danego wiersza bezpośrednio, będziemy się odwoływać do jego pozycji zapisanej w wektorze permutacji. Zwróćmy uwagę na to, że zmieniając wiersze w macierzy A musimy zmieniać też poszczególne współrzędne w wekotrze prawych stron -- b. Złożoność obu przedstawionych powyżej algorytmów wynosi $O(n^3)$.
	
	Teraz kiedy znamy procedurę, która pozwala nam sprowadzić macierz A do macierzy trójkątnej górnej, pojawia się pytanie jak z tą wiedzą rozwiązać układ równań $Ax = b$. W tym celu zastosujemy algorytm podstawiania wstecz. Opiera się on o wzór poniżej.
	$$x_i = \frac{b_i - \sum_{j = i+1}^n (a_{ij} \cdot x_j)}{a_{ii}}$$
	\clearpage
	Widać zatem, że idąc \textit{od końca} ($i=n,\ldots,1$) jesteśmy w stanie obliczyć wszystkie wartości $x$. Złożoność tego algorytmu wynosi $O(n^2)$, a cały proces prowadzący do rozwiązania równania ma złożoność $O(n^3)$ (bo eliminacja Gaussa ma złożoność $O(n^3)$). \\
	Widać tu, że najkosztowniejszym fragmentem opisanego wyżej algorytmu rozwiązywania układu równań jest eliminacja Gaussa. Przedstawiony poniżej rozkład LU będzie umożliwiał rozwiązywanie układu równań dla różnych wektorów prawych stron przy tylko jednym wywołaniu metody eliminacji Gaussa zajmującej $O(n^3)$. Rozwiązywanie kolejnych układów równań z tą samą macierzą A będzie robione w czasie $O(n^2)$.
	
	\section*{Zadanie 1}
	
	Celem tego zadania było napisanie funkcji rozwiązującej układ $\mA\vx = \mB$ metodą eliminacji Gaussa uwzględniającej specyficzną postać macierzy $\mA$ dla dwóch wariantów:
	\begin{enumerate}[a)]
		\item bez wyboru elementu głównego,
		\item z częściowym wyborem elementu głównego.
	\end{enumerate}

	Znając wyżej opisane algorytmy należało zmodyfikować je pod opisaną w treści listy zadań strukturę. Wiemy, że rozwiązanie naszego równania z użyciem niezmodyfikowanych algorytmów ma złożoność $O(n^3)$. Celem jest zrobienie tego samego w czasie $O(n)$. Zakładamy tu, że rozmiar bloku $\ell$ jest stałą. Inne założenie opisane wyżej to założenie, że dostęp do elementu macierzy (Sparse Arrays) jest w czasie stałym.\\
	\textbf{Zastosowane modyfikacje}\\
	Macierz $\mA$ jest macierzą rzadką o specyficznej blokowo-trójdiagonalnej strukturze. Oznacza to, że większość elementów w danej kolumnie nie będzie wymagało zerowania. Znana i uporządkowana struktura pozwala nam na ograniczenie ilości wykonywanych operacji, gdyż są one wymagane tylko dla pewnego ograniczonego obszaru macierzy $\mA$. Wyznaczymy teraz te ograniczenia. W celu przedstawienia metody rozważmy macierz $\mA$ dla $\ell = 4$ i jakiegoś $n$.
$$
	\mA =
	\left(\begin{array}{cccccccccccccc}
	a^1_{11} & a^1_{12} & a^1_{13}  & a^1_{14} & c^1_{11} & 0  & 0  & 0 & 0  & 0  & 0  & 0  & \cdots  \\
	a^1_{21} & a^1_{22} & a^1_{23}  & a^1_{24} & 0 & c^1_{22} & 0  & 0  & 0  & 0  & 0  & 0  & \cdots  \\
	a^1_{31} & a^1_{32} & a^1_{33}  & a^1_{34} & 0  & 0  &  c^1_{33} & 0 & 0  & 0  & 0  & 0  & \cdots  \\
	a^1_{41} & a^1_{42} & a^1_{43}  & a^1_{44} & 0  & 0  & 0 & c^1_{44} & 0  & 0  & 0  & 0  & \cdots   \\
	0 & 0 & b^2_{13}  & b^2_{14} & a^2_{11} & a^2_{12} & a^2_{13}  & a^2_{14} & c^2_{11} & 0  & 0  & 0 &\cdots& \\
	0 & 0 & b^2_{23}  & b^2_{24} & a^2_{21} & a^2_{22} & a^2_{23}  & a^2_{24} & 0 & c^2_{22} & 0  & 0  &\cdots &\\
	0 & 0 & b^2_{33}  & b^2_{34} & a^2_{31} & a^2_{32} & a^2_{33}  & a^2_{34} & 0  & 0  &  c^2_{33} & 0&\cdots &\\
	0 & 0 & b^2_{43}  & b^2_{44} & a^2_{41} & a^2_{42} & a^2_{43}  & a^2_{44} & 0  & 0  & 0 & c^2_{44} &\cdots &\\
	0&0&0&0&0&0& b^3_{13}  & b^3_{14} & a^3_{11} & a^3_{12} & a^3_{13}  & a^3_{14} &\cdots \\
	0&0&0&0&0&0& b^3_{23}  & b^3_{24} & a^3_{21} & a^3_{22} & a^3_{23}  & a^3_{24} &\cdots \\
	0&0&0&0&0&0& b^3_{33}  & b^3_{34} & a^3_{31} & a^3_{32} & a^3_{33}  & a^3_{34} &\cdots \\
	0&0&0&0&0&0& b^3_{43}  & b^3_{44} & a^3_{41} & a^3_{42} & a^3_{43}  & a^3_{44} &\cdots \\
	\vdots & \vdots &\vdots &\vdots &\vdots &\vdots &\vdots &\vdots &\vdots &\vdots &\vdots &\vdots & \ddots \\
	\end{array}\right)
$$

	Kiedy przyjrzymy się czterem ($\ell$) pierwszym kolumnom, widzimy, że musimy w nich wyzerować kolejno 3, 2, 1+4, 0+4 elementów. Zatem pętla która \textit{idzie} po wierszach danej kolumny będzie mogła zakończyć pracę wcześniej. W naszym przypadku na rysunku, w przypadku kolumny pierwszej, pętla będzie mogła zakończyć pracę już po 3 iteracjach, ponieważ wszystkie elementy poniżej $a^1_{41}$ są już zerami.
	Ogólnie jeśli przyjrzymy się $\ell -2$ pierwszym kolumnom to możemy zauważyć, że jedyne elementy niezerowe występują w bloku $\mA_1$, a więc tylko w $\ell$ pierwszych wierszach. Rozpatrując kolejne $\ell$ kolumn widać, że niezerowe elementy będą się znajdować w bloku $\mB_2$ lub $\mC_1$, lub w bloku $\mA_2$, a więc poniżej tych bloków, czyli poniżej wiersza o numerze $2\ell$, nie pojawią się żadne elementy niezerowe. Biorąc kolejne $\ell$ kolumn sytuacja jest podobna -- elementy niezerowe wystąpią \textbf{najniżej} w bloku $\mB_3$ lub $\mA_3$, a więc nie niżej niż wiersz o numerze $3\ell$ licząc od góry ($3\ell$ pierwszych wierszy). Patrząc na przedstawioną wyżej zależność możemy wywnioskować wzór na ostatni element niezerowy w danej kolumnie $k$. 
	$$ ostatni_{wiersz}(k) = min\lbrace \ell + \ell \times \lfloor \frac{k+1}{\ell}\rfloor , n \rbrace, k - \text{indeks kolumny} $$
	Kolejna obserwacja to fakt, że podczas odejmowania wiersza z elementem głównym od innego wiersza nie musimy obliczać tych elementów dla których wiersz główny ma zera. Niech wiersz $k$ będzie naszym wierszem głównym (czyli tym zawierającym element główny), a obecnie eliminowany element będzie w wierszu $i$-tym. Oznacza to, że wykonujemy działanie na wierszach $ R_i \leftarrow R_i -\psi_{ik} \cdot R_k$, gdzie $R_i$ i $R_k$ to odpowiednio $i$-ty i $k$-ty wiersz, a $\psi_{ik}$ to mnożnik (przedstawiony w opisie podstawowej metody eliminacji Gaussa). Teraz widać, że dla $j$-tego elementu wiersza $R_k$ będącego zerem, nazwijmy go $r^k_j = 0$, wykonanie powyższego działania nie zmieni odpowiedniej wartości $j$-tego elementu wiersza $R_i$. Wynika z tego, że pętla która wykonuje to działanie na wierszach może skończyć wcześniej pracę. Teraz wyprowadzimy wzór na ostatnią kolumnę, która może zawierać niezerowy element.\\
	Zauważmy, że ostatnie elementy w wierszach to te leżące na diagonali bloków $\mC$. Są one odległe od diagonali macierzy $\mA$ o dokładnie $\ell$. Zatem ostatni element niezerowy w wierszu $w$ będzie się znajdował w kolumnie o indeksie $min\lbrace \ell + w , n \rbrace $. Podsumowując:
	$$ ostatnia_{kolumna}(w) = min\lbrace \ell + w , n \rbrace, w - \text{indeks wiersza} $$
	Udało się zatem określić ograniczenia pętli w metodzie eliminacji Gaussa, które znacznie zredukują liczbę wykonywanych operacji. Kolejny etap rozwiązywania układu równań to algorytm podstawiania wstecz, który również może zostać zmodyfikowany w celu redukcji wykonywanych operacji.\\
	W algorytmnie tym sumujemy elementy w danym wierszu pomnożone przez pewne liczby. My jednak wiemy, że znaczna część z tych elementów jest zerami, a więc wyniki iloczynów które otrzymamy też będą zerami nie zmianiając tym wartości sumy. Ponadto wiemy na jakiej pozycji występuje ostatni element niezerowy. Jest to zależność wyprowadzona powyżej tzn. wzór na $ostatnia_{kolumna}$. Możemy zatem zakończyć pętlę wcześniej redukując tym liczbę operacji.\\
	Poniżej znajduje się pseudokod omówionego algorytmu w celu podsumowania naszych rozważań.
\begin{algorithm}[h]
	\DontPrintSemicolon
	\SetKwInOut{Input}{Dane wejściowe}
	\SetKwInOut{Output}{Dane wyjściowe}
	\SetKwProg{Fn}{function}{}{}
	\SetKw{KwDownTo}{downto}
	\SetKw{Err}{error}
	
	\SetKwData{L}{$\ell$} 			
	\SetKwData{N}{$n$}    				
	\SetKwData{B}{$\vb$}    		
	\SetKwData{A}{$\mA$}    			
	\SetKwData{X}{$\vx$}
	\SetKwData{F}{f}
	\SetKwData{Z}{$\psi$}
	\SetKwData{I}{i}
	\SetKwData{J}{j}
	\SetKwData{K}{k}
	\SetKwData{Sum}{suma}
	\SetKwData{Col}{$ ostatnia_{kolumna}$}
	\SetKwData{Row}{$ostatni_{wiersz}$}
	\SetKwFunction{ge}{eliminacja\_gaussa}
	\SetKwFunction{Min}{$\min$}
	
	\Input{\\
		\begin{tabularx}{0.85\linewidth}{rcX}
			{\A} & -- & macierz z zadania o opisanej w zadaniu strukturze,\\
			{\B} & -- & wektor prawych stron, \\
			{\N} & -- & rozmiar macierzy \A, \\
			{\L} & -- & rozmiar bloku macierzy \A.  		
		\end{tabularx}
	}
	\Output{\\
		\begin{tabularx}{0.85\linewidth}{rcX}
			{\X}& -- & wektor zawierający rozwiązania układu $\A\X=\B$.
		\end{tabularx}					    			
	}
	\Fn{\ge{\A,~\B,~\N,~\L}}{
		\For{$\K \gets 1$ \KwTo $\N-1$} {
			$\Row\gets\Min\lbrace \L + \L \cdot \left \lfloor\frac{\K + 1}{\ell}\right \rfloor, n \rbrace$\;
			$\Col\gets \Min(\K + \L, \N)$\;
			\For{$\I \gets \K+1$ \KwTo \Row}{
				\If{$\A[\K,\K] = 0$}{\Err współczynnik na przekątnej równy zeru}
				$\Z \gets \frac{\A[\I,\K]}{ \A[\K,\K]} $\;
				$\A[\I,\K] \gets 0 $ \;
				\For{$\J \gets \K+1$ \KwTo \Col}{
					$\A[\I,\J] \gets \A[\I,\J] - \Z \cdot \A[\K,\J]$\;
				}
				$\B[\I] \gets \B[\I] - \Z \cdot \B[\K]$\;
			}
		}
		\For{$\I \gets \N$ \KwDownTo $1$}{
			$\Col\gets \Min(\I+ \L, \N)$\;
			\For{$\J \gets \K+1$ \KwTo $\Col$}{
				$\Sum \gets \Sum + \X[\I] \cdot \A[\I,\J]$\;
			}
			$\X[\I] \gets \frac{\B[\I] - \Sum}{\A[\I,\I]}$\;
		}
		
		\KwRet \X\;
	}
	\caption{Zmodyfikowana metoda eliminacjii Gaussa}
\end{algorithm} 

	Pozostało jeszcze określenie złożoności powyższego algorytmu. Widać, że pierwsza pętla wykona się $n-1$ ($O(n)$) razy, a pierwsza wewnątrz niej maksymalnie $2\ell$ razy. Kolejna pętla wykonująca odejmowanie wierszy wykona się maksymalnie $\ell$ razy. $\ell$ jest stałą, zatem sama eliminacja Gausa wykonuje się w czasie $O(n)$. Teraz przyjrzyjmy się algorytmowi podstawiana wstecz. Zewnętrzna pętla wykona się $O(n)$ razy, a wewnętrzna co najwyżej $\ell$, co daje łącznie $O(n)$. Zatem złożoność całego przedstawionego wyżej algorytmu rozwiązującego układ równań $\mA\vx=\vb$ wynosi $O(n)$.
	\section*{Zadanie 3} 
	
	Celem tego zadania było napisanie funkcji obliczającej współczynniki $a_0,\ldots,a_n$ postaci naturalnej wielomianu interpolacyjnego dla zadanych współczynników $d_0 = f[x_0], d_1 = f[x_0,x_1], \ldots d_n = f[x_0, \ldots, x_n]$ tego wielomianu w postaci Newtona oraz węzłów $x_0, \ldots, x_n$. Ponadto funkcja miała działać w czasie $O(n^2)$.\\
	\textbf{Dane:}
	\begin{enumerate}[]
		\item \texttt{x} -- wektor długości $n+1$ zawierający węzły $x_0, \ldots, x_n$,
		\item \texttt{fx} -- wektor długości $n+1$ zawierający ilorazy różnicowe.
	\end{enumerate}
	\textbf{Oczekiwany wynik:}
	\begin{enumerate}[]
		\item \texttt{a} -- wektor długości $n+1$ zawierający obliczone współczynniki postaci naturalnej.
	\end{enumerate}
	\textbf{Opis:}\\
	Przypomnijmy, że wartości $d_0, d_1, \ldots, d_n$ są współczynnikami wielomianu interpolacyjnego w postaci Newtona. Punktem wyjściowym to wyprowadzenia algorytmu będzie uogólniony algorytm Hornera. Najpierw jednak zapiszmy wielomian interpolacyjny w postaci Newtona: 
	$$ p(x) = \underbrace{d_0 + (x-x_0)(\underbrace{d_1 + (x-x_1)
	(d_2 + \ldots + (x-x_{n-2})(\overbrace{d_{n-1}+(x-x_{n-1})\underbrace{d_n}_{W_n}}^{W_{n-1}}))}_{W_1}}_{W_0}\ldots)$$

	\noindent Idea jest bardzo podobna do wyprowadzania uogólnionego algorytmu Hornera w poprzednim zadaniu. Teraz przyjrzyjmy się zaznaczonym wielomianom $W_k$. Zauważmy też, że ich stopnie rosną (patrząc od góry do dołu).
	\begin{align*}
	W_n(x) & = d_n\nonumber \\
	W_{n-1}(x) &= d_{n-1} + (x-x_{n-1})W_n \nonumber \\
	\ldots & = \ldots \\
	W_k(x) &= d_{k} + (x - x_{k})W_{k+1} \text{ dla } 0\le k<n \nonumber \\
	\ldots & = \ldots \\
	W_0(x) &= p_0(x) \nonumber \\
	\end{align*}
	\clearpage
	Dodatkowo mamy też, że $deg(W_k) = deg(W_{k+1}) + 1$. Obie te obserwacje są kluczowe dla wyprowadzenia algorytmu. Przypomnijmy, że wartości $d_0, d_1, \ldots, d_n$ oraz $x_0, \ldots, x_n$ są danymi, a więc są znane.
	Zastanówmy się jak obliczyć współczynniki wielomianu $W_{n-1}$ w postaci naturalnej. Mamy $deg(W_{n-1}) = deg(W_n) + 1 = 0 + 1 = 1$, a zatem $W_{n-1}$ możemy ogólnie zapisać jako $W_{n-1}(x) = a_{0}x^0 + a_{1}x^1$. Z drugiej strony patrząc na tabelę wyżej możemy go zapisać jako $$W_{n-1}(x) = d_{n-1} + (x - x_{n-1})W_n = d_{n-1} + (x - x_{n-1})d_n = d_{n-1} + xd_n - x_{n-1}d_n = 
	(d_{n-1} - d_nx_{n-1})x^0 + (d_{n})x^1 $$
	Otrzymaliśmy współczynniki naturalne wielomianu $W_{n-1}$. Konkretniej mamy, że $a_0=d_{n-1} - d_nx_{n-1}$ i $a_1=d_{n}$. Zróbmy to samo dla $W_{n-2}$. $$W_{n-2}(x)=d_{n-2}+(x-x_{n-2})W_{n-1} =d_{n-2}+(x-x_{n-2})(a_{0}x^0 + a_{1}x^1) = $$
	$$(d_{n-2} - x_{n-2}a_0)x^0 + (a_0-a_1x_{n-2})x^1 + a_1x^2$$
	Obliczyliśmy współczynniki $W_{n-2}$ w postaci naturalnej. Jeśli ten wielomian zapiszemy jako $W_{n-2} = b_0x^0+b_1x^1+b_2x^2$ to współczynniki będą następujące: $b_0 = d_{n-2} - x_{n-2}a_0$, $b_1=a_0-a_1x_{n-2}$, $b_2=a_1$.
	Widzimy zatem, że współczynniki przy najwyższej potędze wielomianów $W_{n-1}$ i $W_{n-2}$ są sobie równe. Ogólnie mamy, że współczynniki przy najwyższej potędze dla wielomianów $W_{k}$ i $W_{k-1}$ są sobie równe. Inna kluczowa obserwacja to fakt, że licząc współczynniki naturalne wielomianu $W_{n-2}$ korzystaliśmy tylko z danych i ze współczynników naturalnych wielomianu $W_{n-1}$. Podobnie obliczając współczynniki wielomianu $W_{n-1}$ korzystaliśmy tylko z danych i współczynników wielomianu $W_{n}$. Widzimy zatem, że współczynniki naturalne wielomianu $W_k$ jesteśmy w stanie obliczyć znając współczynniki wielomianu $W_{k+1}$. Oznacza to, że możemy to zrobić używając jednej tablicy. Ponadto jesteśmy w stanie zrobić to w czasie $O(n)$. W szczególności możemy obliczyć współczynniki wielomianu $W_0=p_0$ w postaci naturalnej licząc kolejno współczynniki wielomianów $W_n$, $W_{n-1}$, $\ldots$, $W_1$, $W_0$ każdy w czasie $O(n)$ co daje łączny czas $O(n^2)$. Teraz dla podsumowania pseudokod.\\
	\noindent\textbf{Pseudokod algorytmu}\\
	\begin{algorithm}[h]
		\DontPrintSemicolon
		\SetKw{KwDownTo}{downto}
		\SetKwProg{Fun}{function}{}{}
		\SetKwFunction{LEN}{length}
		\SetKwFunction{F}{naturalna}
		\Fun{\F{$x$, $fx$}} {
			$n \gets \LEN{fx}$-1\;
			$a[n] \gets fx[n]$\;
			\For{$i \gets n-1$ \KwDownTo $0$} {
				$a[i] \gets fx[i] - a[i+1] * x[i]$\; 
				\For{$j \gets i+1$ \KwTo $n-1$} {
					$a[j] \gets a[j] - a[j+1] * x[i]$\; 	
				}	
			}
			\KwRet $a$\;
		}
		
		\caption{Obliczanie współczynników naturalnych wielomianu interpolacyjnego.}
	\end{algorithm}	
	
	
	\clearpage
	
	\section*{Zadanie 4}

	Celem zadania było napisanie funkcji interpolującej zadaną funkcję $f(x)$ w przedziale $[a, b]$ za pomocą wielomianu interpolacyjnego stopnia $n$ w postaci Newtona, a także rysującej wykresy funkcji $f$ oraz otrzymanego wielomianu interpolacyjnego. W interpolacji funkcji należało użyć węzłów równoodległych.\\
	\textbf{Dane:}
	\begin{enumerate}[]
		\item \texttt{f} -- zadana funkcja,
		\item \texttt{a, b} --  przedział interpolacji,
		\item \texttt{n} --  stopień wielomianu interpolacyjnego.
	\end{enumerate}
	\textbf{Oczekiwany wynik:}
	\begin{enumerate}[]
		\item -- wykres funkcji $f$ oraz wielomianu interpolacyjnego w przedziale $[a,b]$.
	\end{enumerate}
	\textbf{Opis:}\\
	Na początku wyznaczyłem węzły interpolacyjne $x_1, \ldots, x_{n+1}$ w taki sposób aby odległość między nimi wynosiła $\frac{b-a}{n}$. Następnie obliczyłem wartości funkcji w tych punktach tj. $f(x_1), \ldots, f(x_{n+1})$.
	W celu obliczenia ilorazów różnicowych posłużyłem się funkcją z zadania pierwszego -- \texttt{ilorazyRoznicowe}. Następnie użyłem funkcji z zadania drugiego tj. \texttt{warNewton} do obliczenia wartości wielomianu interpolacyjnego w potrzebnych punktach. W celu uzyskania dokładniejszego wykresu, punkty dla których rysowałem wykres musiałem zagęścić. Zrobiłem to mnożąc dane $n$ razy obrany przeze mnie parametr gęstości równy 40. Dzięki temu uzyskałem dokładniejsze wykresy.
	
	
	\section*{Zadanie 5}
	Celem zadania było przetestowanie funkcji \texttt{rysujNnfx(f,a,b,n)} (z zadania 4) na następujących przykładach:
	\begin{enumerate}[(a)]
		\item $f(x) = e^x$, $[a, b] = [0,1]$, $n \in \{5,10,15\}$,
		\item $f(x) = x^2\sin{x}$, $[a, b] = [-1,1]$, $n \in \{5,10,15\}$.
	\end{enumerate}
	Poniżej narysowane wykresy dla obu funkcji. Na przykładach tych funkcji widać, że wybranie równoodległych węzłów dało bardzo dokładne przybliżenia funkcji. Dla żadnego z wykresów nie zaobserwowano rozbieżności. Kolejna rzecz warta zaobserwowania to fakt, że dla wszystkich wartości n funkcje były bardzo dobrze przybliżone.
	
		\begin{figure}[!htbp]
	\centering

	\caption*{Wykres funkcji $e^{x}$ i jej wielomianu interpolacyjnego dla danego stopnia $n$}
\end{figure}		

\begin{figure}[!htbp]
	\centering
%	\subfloat[1.][$n=5$]{\includegraphics[width=0.5\textwidth]{plots/task5plotf2_5.png}} \hfill
%	\subfloat[2.][$n=10$]{\includegraphics[width=0.5\textwidth]{plots/task5plotf2_10.png}} \hfill
%	\subfloat[3.][$n=15$]{\includegraphics[width=0.5\textwidth]{plots/task5plotf2_15.png}} \hfill
	\caption*{Wykres funkcji $x^2\sin{x}$ i jej wielomianu interpolacyjnego dla danego stopnia $n$}
\end{figure}	





	\clearpage
	
	\section*{Zadanie 6}
	
	Celem zadania było przetestowanie funkcji \texttt{rysujNnfx(f,a,b,n)} (z zadania 4) na następujących przykładach:
	\begin{enumerate}[(a)]
		\item $f(x) = |x|$, $[a, b] = [-1,1]$, $n \in \{5,10,15\}$,
		\item $f(x) = \frac{1}{1+x^2}$, $[a, b] = [-5,5]$, $n \in \{5,10,15\}$.
	\end{enumerate}
Wykresy otrzymane za pomocą metody \texttt{rysujNnfx(f,a,b,n)} prezentują poniższe wykresy.
\begin{figure}[h]
	\centering
%	\subfloat[1.][$n=5$]{\includegraphics[width=0.5\textwidth]{plots/task6plotf1_5.png}} \hfill
%	\subfloat[2.][$n=10$]{\includegraphics[width=0.5\textwidth]{plots/task6plotf1_10.png}} \hfill
%	\subfloat[3.][$n=15$]{\includegraphics[width=0.5\textwidth]{plots/task6plotf1_15.png}} \hfill
%	\subfloat[4.][$n=20$]{\includegraphics[width=0.5\textwidth]{plots/task6plotf1_20.png}} \hfill
	\caption*{Wykres funkcji $|x|$ i jej wielomianu interpolacyjnego dla danego stopnia $n$}
	\label{fig:3}
\end{figure}		

\begin{figure}[h]
	\centering
%	\subfloat[1.][$n=5$]{\includegraphics[width=0.5\textwidth]{plots/task6plotf2_5.png}} \hfill
%	\subfloat[2.][$n=10$]{\includegraphics[width=0.5\textwidth]{plots/task6plotf2_10.png}} \hfill
%	\subfloat[3.][$n=15$]{\includegraphics[width=0.5\textwidth]{plots/task6plotf2_15.png}} \hfill
%	\subfloat[4.][$n=20$]{\includegraphics[width=0.5\textwidth]{plots/task6plotf2_20.png}} \hfill
	\caption*{Wykres funkcji $\frac{1}{1+x^2}$ i jej wielomianu interpolacyjnego dla danego stopnia $n$}
	\label{fig:4}
\end{figure}

Widać, że dla funkcji $|x|$ pojawiają się większe odchylenia niż dla funkcji z zadania poprzedniego. Widać też, że wraz ze zwiększaniem stopnia wielomianu odchylenia/błędy, w szczególności na końcach przedziału, znacznie wzrastają. Dla $n=20$ te odchylenia są już na tyle duże, że wykres traci na czytelności. Dla drugiej funkcji sytuacja wygląda tak samo -- wraz ze zwiększaniem stopnia wielomianu błąd rośnie, a błędy najbardziej rosną na końcach przedziału. Jest to sprzeczne z intuicją, ponieważ zwiększajac stopień wielomianu interpolacyjnego oczekujemy lepszego przybliżenia. Zaobserwowane zjawisko nosi nazwę zjawiska Rungego. (Sama funkcja $\frac{1}{1+x^2}$ nazywana jest funkcją Rungego). Polega ono na tym, że dla pewnych funkcji błąd wielomianu
interpolacyjnego wyliczonego za pomocą równoodległych węzłów dąży do nieskończoności wraz ze
wzrostem stopnia tego wielomianu interpolacyjnego.\\
Pojawia się pytanie czy można poprawić dokładność wielomianów interpolacyjnych dla takich funkcji. Z pomocą przychodzą nam węzły Czebyszewa będące pierwiastkami wielomianów Czebyszewa pierwszego rodzaju. Ich użycie zwiększa liczbę węzłów w miejscach, które są trudniejsze do przybliżenia, czyli między innymi na końcach przedziału. Skutkuje to otrzymaniem dokładniejszego przybliżenia. Poniżej znajdują się wykresy z wielomianami interpolacyjnymi stworzonymi na podstawie węzłów Czebyszewa.

\begin{figure}[h]
	\centering
%	\subfloat[1.][$n=5$]{\includegraphics[width=0.5\textwidth]{plots/task6ChebyshevPlotf1_5.png}} \hfill
%	\subfloat[2.][$n=10$]{\includegraphics[width=0.5\textwidth]{plots/task6ChebyshevPlotf1_10.png}} \hfill
%	\subfloat[3.][$n=15$]{\includegraphics[width=0.5\textwidth]{plots/task6ChebyshevPlotf1_15.png}} \hfill
%	\subfloat[4.][$n=20$]{\includegraphics[width=0.5\textwidth]{plots/task6ChebyshevPlotf1_20.png}} \hfill
	\caption*{Wykres funkcji $|x|$ i jej wielomianu interpolacyjnego skonstruowanego przy pomocy węzłów Czebyszewa}
	\label{fig:4}
\end{figure}
\begin{figure}[h]
	\centering
%	\subfloat[1.][$n=5$]{\includegraphics[width=0.5\textwidth]{plots/task6ChebyshevPlotf2_5.png}} \hfill
%	\subfloat[2.][$n=10$]{\includegraphics[width=0.5\textwidth]{plots/task6ChebyshevPlotf2_10.png}} \hfill
%	\subfloat[3.][$n=15$]{\includegraphics[width=0.5\textwidth]{plots/task6ChebyshevPlotf2_15.png}} \hfill
%	\subfloat[4.][$n=20$]{\includegraphics[width=0.5\textwidth]{plots/task6ChebyshevPlotf2_20.png}} \hfill
	\caption*{Wykres funkcji $\frac{1}{1+x^2}$ i jej wielomianu interpolacyjnego stworzonego przy pomocy węzłów Czebyszewa}
	\label{fig:4}
\end{figure}



\end{document}